[
  {
    "id": "amazon-pricing",
    "title": "Data Scientist II \u2014 Pricing & Promotion Optimization (Amazon Devices)",
    "area": "Production ML, Optimization, Forecasting",
    "tags": [
      "Amazon",
      "pricing",
      "promotions",
      "time series",
      "forecasting",
      "optimization",
      "MILP",
      "N-BEATS"
    ],
    "summary": "Built large-scale pricing and promotion optimization models for Amazon Devices, combining demand forecasting and mixed-integer optimization to drive multi-million dollar savings.",
    "details": "Developed a Mixed Integer Linear Programming (MILP) model supporting 20+ business constraints to optimize annual promotion planning for all devices, achieving around $3M cost savings in the first year. Designed and implemented N-BEATS time series models to forecast sales for new device launches, solving cold-start issues by leveraging related signals and historical launches. Owned end-to-end pipelines on AWS (EMR, S3, Lambda, etc.), making these models production-ready and monitored."
  },
  {
    "id": "realtor-marketing",
    "title": "Staff Data Scientist \u2014 Marketing Attribution (Realtor.com)",
    "area": "Marketing attribution, experimentation, MLOps",
    "tags": [
      "Realtor",
      "attribution",
      "LSTM",
      "A/B testing",
      "Flask",
      "EC2"
    ],
    "summary": "Led marketing attribution and experimentation tools at Realtor.com, building models and services that informed channel spend and accelerated campaign learning.",
    "details": "Created a marketing attribution model using LSTM with ~86% AUC to measure channel-level impact. Built a real-time A/B testing impact sizing tool with Flask and EC2 that reduced time to market for campaigns by about two weeks. Set up cloud data pipelines with Lambda, Sagemaker, Glue, and EMR to automate reports and scale models for marketing stakeholders."
  },
  {
    "id": "flipkart-search-reco",
    "title": "Senior Data Scientist \u2014 Search & Recommendations (Flipkart)",
    "area": "Recommendation systems, experimentation",
    "tags": [
      "recommendations",
      "search",
      "random forest",
      "SMOTE",
      "experimentation",
      "A/B testing"
    ],
    "summary": "Improved onsite search and recommendation quality at Flipkart using ML models and experimentation to boost conversion and cross-sell performance.",
    "details": "Implemented a Random Forest model with SMOTE on visit-level data to understand user conversion, improving click conversion by ~45 bps. Developed new affinity calculations for cross-selling items that drove a 14% increase in items with recommendations. Designed A/B experiments for several product launches and created an internal A/B testing tool to centralize metrics and decision-making."
  },
  {
    "id": "walmart-forecasting",
    "title": "Data Scientist \u2014 Retail Pricing & Assortment (Walmart Labs)",
    "area": "Time series, forecasting, anomaly detection",
    "tags": [
      "Walmart",
      "time series",
      "ARIMAX",
      "VAR",
      "forecasting",
      "anomaly detection"
    ],
    "summary": "Built time-series forecasting and anomaly detection tools at Walmart Labs to support pricing, assortment, and operational decisions across millions of SKUs.",
    "details": "Developed ARIMAX and VAR models to forecast volume lift for ~6.5M products with about 74% forecast accuracy, supporting pricing and assortment planning. Implemented STL decomposition-based sales anomaly detection and root cause analysis. Built an end-to-end pricing pipeline on Hadoop streaming, reducing processing time from ~14 hours to 8 hours."
  },
  {
    "id": "recology-routing",
    "title": "Data Science Intern \u2014 Routing Optimization (Recology)",
    "area": "Routing optimization, clustering, geospatial ML",
    "tags": [
      "Recology",
      "routing",
      "DBSCAN",
      "XGBoost",
      "geospatial"
    ],
    "summary": "Optimized garbage collection routes and operations at Recology using clustering, prediction, and computer vision.",
    "details": "Automated sequencing of garbage pickup routes using geospatial data and DBSCAN clustering, reducing planning effort from two days to about 20 minutes. Predicted collection times with XGBoost and Isolation Forest, increasing route ROI by roughly 5%. Built a contract summarization tool using T5 and a garbage classification model using ResNet-50 with ~95% accuracy to classify glass/plastic/cardboard/paper/trash."
  },
  {
    "id": "experiments-llm-mcp",
    "title": "Experiment Design Agent & LLM Personalization",
    "area": "LLMs, agents, experimentation, personalization",
    "tags": [
      "LLM",
      "MCP",
      "agents",
      "experimentation",
      "RAG",
      "personalization"
    ],
    "summary": "Built LLM and agent-based systems for experiment design and personalization, comparing MCP-style tools with classic RAG pipelines.",
    "details": "Designed an MCP-style agent that automated experiment design for product teams: it queried traffic data, invoked a Lambda-based power and sample-size engine, and mapped catalog data so natural language inputs (e.g., 'run an Alexa experiment') resolve to internal identifiers. Prototyped LLM-driven personalization flows with retrieval over product and behavioral data, comparing MCP vs. RAG orchestrations, and focused on guardrails for factuality, latency, and cost."
  },
{
  "id": "causal-ab-inference",
  "title": "Causal Inference for A/B-like Settings",
  "area": "Causal inference, experimentation",
  "tags": [
    "causal inference",
    "A/B testing",
    "experimentation"
  ],
  "summary": "Applied an S-Learner causal ML framework to estimate incremental lift for Amazon product changes in situations where classic A/B tests were underpowered or infeasible.",
  "details": "Trained an XGBoost S-Learner with treatment indicators to generate counterfactual predictions and quantify incremental impact for scenarios such as accessory attach, while adjusting for seasonality and holiday patterns. Combined experiment design intuition with uplift-style reasoning to deliver clear, actionable insights to product and marketing partners."
}
,  {
    "id": "resume",
    "title": "Resume — Shruti Roy",
    "area": "Full resume data",
    "tags": [
      "resume",
      "profile",
      "experience",
      "education",
      "skills"
    ],
    "summary": "Structured resume JSON for Shruti Roy with summary, experience, education, and skills sections.",
    "details": {
      "data": {
        "name": "Shruti Roy",
        "headline": "Senior Data Scientist",
        "email": "shrutid203@gmail.com",
        "phone": "(425)-628-3203",
        "location": "Seattle, WA",
        "linkedin": "linkedin.com/in/shruti-roy/",
        "summary": "Senior Data Scientist specializing in large-scale ML systems (200M+ customers), causal inference, and end-to-end model deployment on AWS. Experienced in building ranking models, LLM/agent systems, A/B testing automation, and time-series forecasting for high-stakes product decisions.",
        "openaiKey": "",
        "skills": [
          "AWS",
          "Pytorch",
          "FastAPI",
          "A/B Testing",
          "Scikit-Learn",
          "EMR",
          "SQL",
          "Flask",
          "Ollama",
          "FASAI",
          "Spark",
          "Hadoop",
          "Tableau"
        ],
        "experience": [
          {
            "bullets": [
              "Increased homepage campaign CTR by 18% across 200M weekly customers by owning the LightGBM ranking model end-to-end and architecting a scalable Lambda+EMR+SQS scoring pipeline integrated with internal APIs.",
              "Reduced A/B experiment setup time by 85% (days to ~10 minutes) for 30+ PMs by developing an MCP-based experiment-design agent automating statistical calculations, guardrail checks, and results interpretation.",
              "Improved anomaly detection precision by 22% across 100+ devices by engineering an uncertainty-aware sales deviation monitoring system using Nixtla to distinguish true demand drops from seasonal or pricing effects.",
              "Reduced launch forecast error by 15% for new devices by developing an N-BEATS forecasting pipeline that mitigated cold-start issues and improved inventory and supply chain planning accuracy."
            ],
            "role": "Senior Data Scientist",
            "company": "Amazon",
            "location": "Seattle, USA",
            "start": "June 2022",
            "end": "Present"
          },
          {
            "bullets": [
              "Drove a 13% lift in ROI by enabling optimized channel spend allocation using an LSTM-based attribution model (PR AUC: 76.3%), deployed through serverless pipelines (Lambda, SageMaker, EMR) for consistent and scalable inference.",
              "Drove a 7.8% lift in rental lead conversion by building a natural-language cohort engine using behavioral embeddings and OpenSearch vector search to retrieve semantically similar customers from NL-defined seed behaviors.",
              "Reduced manual reporting effort by ~35% by building production ETL pipelines using AWS Glue, EMR, and automated dashboards, standardizing analytics workflows for marketing stakeholders."
            ],
            "role": "Staff Data Scientist (Marketing Data Science)",
            "company": "Realtor.com",
            "location": "Seattle, USA",
            "start": "Sept. 2021",
            "end": "June 2022"
          },
          {
            "bullets": [
              "Improved route ROI by 8% using XGBoost and Isolation Forest models to forecast pickup times and anticipate operational delays.",
              "Accelerated contract review cycles by 30% through a T5-based summarization model extracting key legal clauses from long-form service agreements.",
              "Developed a ResNet-50 waste-classification model achieving 95% accuracy across five material categories, enabling future automation of recycling workflows."
            ],
            "role": "Data Science Intern (Routing Optimization)",
            "company": "Recology",
            "location": "San Francisco, USA",
            "start": "Jan. 2021",
            "end": "Aug. 2021"
          },
          {
            "role": "Senior Data Scientist (Search and Recommendation)",
            "company": "Flipkart E-commerce",
            "location": "Bangalore, India",
            "start": "Aug. 2018",
            "end": "July 2020",
            "bullets": [
              "Increased recommendation coverage by 14% and improved units sold by 10% by leading two DSs in building collaborative filtering models for private-label products.",
              "Improved launch success metrics by driving experiment design and analysis for five major initiatives and developing an internal A/B experimentation tool that reduced setup time by 30%.",
              "Reduced anomaly investigation time by 25% by deploying STL-based decomposition models to isolate demand shocks and seasonal patterns across categories."
            ]
          },
          {
            "role": "Data Scientist (Retail Pricing and Assortment analytics)",
            "company": "Walmart Labs",
            "location": "Bangalore, India",
            "start": "Nov. 2016",
            "end": "Aug. 2018",
            "bullets": [
              "Forecasted volume lift for 6.5M+ products using ARIMAX and VAR models (74% accuracy), enabling pricing and assortment teams to improve planning accuracy by ~12%.",
              "Accelerated executive decision-making by developing Tableau dashboards to visualize anomalies, forecasts, and root-cause analyses across high-volume product categories."
            ]
          },
          {
            "role": "Earlier Career",
            "company": "",
            "location": "",
            "start": "",
            "end": "",
            "bullets": [
              "Lead Product Analyst, Ola Cabs (2016) — Increased shuttle-route utilization by 14% by optimizing route structures using linear programming under real-world demand and capacity constraints.",
              "Business Analyst, ZS Associates (2014–2016) — Built a statistical governance model using linear regression to ensure equitable incentive payouts and reduce compensation disputes by ~10%."
            ]
          }
        ],
        "education": [
          {
            "degree": "Masters in Data Science",
            "school": "University of San Francisco",
            "location": "3.8/4 GPA",
            "start": "Aug. 2020",
            "end": "Aug. 2021",
            "details": ""
          },
          {
            "degree": "B.E(Hons.) Electronics",
            "school": "Birla Institute of Technology and Science",
            "location": "",
            "start": "Aug. 2010",
            "end": "May 2014",
            "details": ""
          }
        ]
      },
      "sectionOrder": [
        "summary",
        "experience",
        "education",
        "skills"
      ]
    }
  },
  {
    "id": "proj-two-tower",
    "title": "Two-Tower Recommender System",
    "area": "Personal Project",
    "tags": [
      "retrieval",
      "recommendations",
      "two-tower",
      "similarity search",
      "Pytorch"
    ],
    "summary": "Two-tower retrieval model that learns user and item embeddings separately and ranks candidates via dot-product similarity.",
    "details": "GitHub: https://github.com/shrutiroyai/two_tower_retrieval. Trained a two-tower architecture to generate user and item vectors for fast candidate generation. Implemented negative sampling, batch inference, and ANN-ready embeddings so the model can plug into downstream ranking or vector-search layers."
  },
  {
    "id": "proj-twiml-buzzer",
    "title": "Automated Entry Buzzer with TwiML",
    "area": "Personal Project",
    "tags": [
      "Twilio",
      "TwiML",
      "voice",
      "automation",
      "PHP",
      "AWS"
    ],
    "summary": "Automated apartment entry calls with a Twilio-powered voice flow that validates a passcode and triggers the buzzer.",
    "details": "GitHub: https://github.com/shrutiroyai/Programing-Voice-using-TwiML. Set up a Twilio number that answers the building entry phone, checks a shared passcode, and automatically buzzes visitors in. Hosted the PHP webhook on AWS with configurable codes to avoid missed early-morning calls."
  },
  {
    "id": "proj-marketing-mix",
    "title": "Marketing Mix Modeling & Adstock",
    "area": "Personal Project",
    "tags": [
      "marketing mix modeling",
      "adstock",
      "attribution",
      "time series",
      "Python"
    ],
    "summary": "Built weekly MMMs with adstock rate estimation for camera accessories, home audio, and gaming accessories.",
    "details": "GitHub: https://github.com/shrutiroyai/Adstock-Rate-Calculation-and-Marketing-Mix-Modelling. Modeled channel contributions using adstock transformations, saturation, and base vs. incremental demand separation at weekly granularity to guide spend allocation across three product sub-categories."
  }
]
